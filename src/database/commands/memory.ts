/**
 * Memory Infrastructure
 * Creates and manages AI memory layer
 */

import * as path from 'path';
import { UnifiedSchemaInfo } from '../extractors/index.js';
import { ensureDir, writeFileSafe, readFileSafe } from '../../core/index.js';
import * as fs from 'fs/promises';
import { fileURLToPath } from 'url';

export interface SessionContext {
  sessionId: string;
  timestamp: string;
  schemaHash: string;
  schemaVersion?: string;
  codebaseHash?: string;
  codebaseStats?: { files: number; loc: number };
  currentTask?: {
    description: string;
    status: 'in_progress' | 'paused' | 'completed';
    progress: number;
    nextSteps: string[];
  };
  recentChanges: Array<{
    table: string;
    change: string;
    timestamp: string;
  }>;
  pendingQueries: string[];
  discoveries: string[];
}

export class MemoryInfrastructure {
  /**
   * Create memory directory structure
   */
  async createMemoryStructure(outputDir: string): Promise<void> {
    const dirs = [
      path.join(outputDir, 'memory', 'checkpoints'),
      path.join(outputDir, 'memory', 'learnings'),
      path.join(outputDir, 'decisions'),
      path.join(outputDir, 'context'),
      path.join(outputDir, 'state'),
    ];

    for (const dir of dirs) {
      await ensureDir(dir);
    }
  }

  /**
   * Initialize memory files
   */
  async initializeMemoryFiles(outputDir: string, schema: UnifiedSchemaInfo): Promise<void> {
    // Initialize LEARN.md
    const learningsPath = path.join(outputDir, 'memory', 'LEARN.md');
    const learningsContent = this.createInitialLearnings(schema);
    await writeFileSafe(learningsPath, learningsContent);

    // Initialize session-history.md
    const historyPath = path.join(outputDir, 'memory', 'session-history.md');
    const historyContent = this.createInitialHistory();
    await writeFileSafe(historyPath, historyContent);

    // Initialize schema-evolution.md
    const evolutionPath = path.join(outputDir, 'memory', 'schema-evolution.md');
    const evolutionContent = this.createSchemaEvolution(schema);
    await writeFileSafe(evolutionPath, evolutionContent);

    // Initialize codebase-evolution.md
    const codebaseEvolutionPath = path.join(outputDir, 'memory', 'codebase-evolution.md');
    // Initial hash/stats are unknown at pure DB init time, using placeholders
    const codebaseEvolutionContent = this.createCodebaseEvolution('pending', { files: 0, loc: 0 });
    await writeFileSafe(codebaseEvolutionPath, codebaseEvolutionContent);

    // Create initial SESSION_CONTEXT.json
    const contextPath = path.join(outputDir, 'context', 'SESSION_CONTEXT.json');
    const sessionContext = this.createSessionContext(schema);
    await writeFileSafe(contextPath, JSON.stringify(sessionContext, null, 2));
  }

  /**
   * Copy template files to output directory
   */
  async copyTemplateFiles(templatesDir: string, outputDir: string): Promise<void> {
    const templateFiles = [
      'edge-cases.md',
      'state/CURRENT_STATE.md',
      'memory/checkpoint-patterns.md',
    ];
    const commandDir = path.dirname(fileURLToPath(import.meta.url));
    const candidateDirs = [
      templatesDir,
      path.resolve(commandDir, '..', 'templates'),
      path.resolve(commandDir, '..', '..', 'database', 'templates'),
    ];
    const fallbacks = this.getTemplateFallbacks();

    for (const file of templateFiles) {
      const destPath = path.join(outputDir, file);
      let copied = false;

      for (const baseDir of candidateDirs) {
        try {
          const srcPath = path.join(baseDir, file);
          const content = await readFileSafe(srcPath);
          await ensureDir(path.dirname(destPath));
          await writeFileSafe(destPath, content);
          copied = true;
          break;
        } catch {
          // Try next candidate path
        }
      }

      if (!copied && fallbacks[file]) {
        await ensureDir(path.dirname(destPath));
        await writeFileSafe(destPath, fallbacks[file]);
      }
    }
  }

  private getTemplateFallbacks(): Record<string, string> {
    return {
      'edge-cases.md': `# Edge Cases

This file captures known project edge cases and mitigations.

## Add Cases

- Scenario:
- Impact:
- Mitigation:
`,
      'state/CURRENT_STATE.md': `# Current State

Generated by DevMind.

- Status: initializing
- Last Updated: ${new Date().toISOString()}
- Next Step: run \`devmind generate\` or \`devmind scan\`
`,
      'memory/checkpoint-patterns.md': `# Checkpoint Patterns

Use checkpoints to preserve progress across sessions.

## Recommended

- Save a checkpoint before large refactors.
- Include a short message describing intent.
`,
    };
  }

  /**
   * Create initial learnings file
   */
  private createInitialLearnings(schema: UnifiedSchemaInfo): string {
    return `# Project Learnings
        
> Auto-generated on ${new Date().toISOString()}

This file accumulates technical learnings, architectural decisions, and discovered patterns.

## Initial Schema Analysis

- **Tables:** ${schema.tables.length}
- **Database Type:** ${schema.databaseType}
- **Schema Name:** ${schema.schemaName || 'N/A'}

## Codebase Knowledge

- **Architecture:** (Pending analysis)
- **Patterns:** (Pending analysis)

## Patterns

See \`BUSINESS_LOGIC.md\` for detected patterns.

## Sessions

### Session 1 - ${new Date().toISOString().split('T')[0]}
- Initial schema generation
- Detected business patterns
- Created memory infrastructure

---

*Add new learnings below. Each session should append discoveries, edge cases, and best practices.*
`;
  }

  /**
   * Create initial session history
   */
  private createInitialHistory(): string {
    return `# Session History

> Recent database context sessions

## ${new Date().toISOString().split('T')[0]} - Initial Generation

**Status:** Completed  
**Agent:** devmind-db v1.0.3

**Actions:**
- Generated schema context
- Created memory infrastructure
- Detected business patterns

**Discoveries:**
- Schema structure analyzed
- Memory layer initialized

---

*New sessions will be appended below*
`;
  }

  /**
   * Create schema evolution tracking
   */
  private createSchemaEvolution(schema: UnifiedSchemaInfo): string {
    const schemaHash = this.calculateSchemaHash(schema);

    return `# Schema Evolution

> Track schema changes over time

## ${new Date().toISOString().split('T')[0]} - Baseline

**Schema Hash:** \`${schemaHash}\`  
**Tables:** ${schema.tables.length}  
**Database:** ${schema.databaseType}

### Tables Created
${schema.tables.map((t) => `- ${t.name} (${t.columns.length} columns)`).join('\n')}

---

*Schema changes will be tracked below*
`;
  }

  /**
   * Create codebase evolution tracking
   */
  createCodebaseEvolution(hash: string, stats?: { files: number; loc: number }): string {
    return `# Codebase Evolution

> Track codebase structure changes over time

## ${new Date().toISOString().split('T')[0]} - Baseline

**Codebase Hash:** \`${hash}\`
**Files:** ${stats?.files || 0}
**LOC:** ${stats?.loc || 0}

---

*Codebase changes will be tracked below*
`;
  }

  /**
   * Create initial session context
   */
  private createSessionContext(schema: UnifiedSchemaInfo): SessionContext {
    return {
      sessionId: `session-${Date.now()}`,
      timestamp: new Date().toISOString(),
      schemaHash: this.calculateSchemaHash(schema),
      schemaVersion: '1.0.0',
      recentChanges: [],
      pendingQueries: [],
      discoveries: [
        `Schema initialized with ${schema.tables.length} tables`,
        'Memory infrastructure created',
        'Business patterns detected',
      ],
    };
  }

  /**
   * Calculate schema hash for drift detection
   */
  calculateSchemaHash(schema: UnifiedSchemaInfo): string {
    const payload = schema.tables
      .map((t) => `${t.name}:${t.columns.map((c) => `${c.name}:${c.type}`).join(',')}`)
      .join('|');

    // Simple hash (replace with crypto.createHash in production)
    let hash = 0;
    for (let i = 0; i < payload.length; i++) {
      const char = payload.charCodeAt(i);
      hash = (hash << 5) - hash + char;
      hash = hash & hash; // Convert to 32bit integer
    }

    return Math.abs(hash).toString(16);
  }

  /**
   * Save checkpoint
   */
  async saveCheckpoint(
    outputDir: string,
    context: SessionContext,
    message?: string,
  ): Promise<string> {
    const filename = `checkpoint-${Date.now()}.json`;
    const filepath = path.join(outputDir, 'memory', 'checkpoints', filename);

    const checkpoint = {
      ...context,
      message,
      savedAt: new Date().toISOString(),
    };

    await writeFileSafe(filepath, JSON.stringify(checkpoint, null, 2));
    return filepath;
  }

  /**
   * Restore latest checkpoint
   */
  async restoreLatestCheckpoint(outputDir: string): Promise<SessionContext | null> {
    const checkpointsDir = path.join(outputDir, 'memory', 'checkpoints');

    try {
      const files = await fs.readdir(checkpointsDir);
      const checkpointFiles = files
        .filter((f) => f.startsWith('checkpoint-') && f.endsWith('.json'))
        .sort();

      if (checkpointFiles.length === 0) {
        return null;
      }

      const latest = checkpointFiles[checkpointFiles.length - 1];
      const filepath = path.join(checkpointsDir, latest);
      const content = await readFileSafe(filepath);

      return JSON.parse(content) as SessionContext;
    } catch (error) {
      return null;
    }
  }

  /**
   * Update session context
   */
  async updateSessionContext(outputDir: string, updates: Partial<SessionContext>): Promise<void> {
    const contextPath = path.join(outputDir, 'context', 'SESSION_CONTEXT.json');
    try {
      const content = await readFileSafe(contextPath);
      const context: SessionContext = JSON.parse(content);
      const updatedContext = { ...context, ...updates, timestamp: new Date().toISOString() };
      await writeFileSafe(contextPath, JSON.stringify(updatedContext, null, 2));
    } catch (error) {
      // Context doesn't exist, create minimal one
      const minimalContext: SessionContext = {
        sessionId: `session-${Date.now()}`,
        timestamp: new Date().toISOString(),
        schemaHash: 'pending', // Placeholder until DB scan
        recentChanges: [],
        pendingQueries: [],
        discoveries: ['Session initialized from codebase scan'],
        ...updates,
      } as SessionContext;

      await ensureDir(path.dirname(contextPath));
      await writeFileSafe(contextPath, JSON.stringify(minimalContext, null, 2));
    }
  }
  /**
   * Update codebase evolution
   */
  async updateCodebaseEvolution(
    outputDir: string,
    hash: string,
    stats: { files: number; loc: number },
  ): Promise<void> {
    const evolutionPath = path.join(outputDir, 'memory', 'codebase-evolution.md');
    let content = '';

    try {
      content = await readFileSafe(evolutionPath);
    } catch {
      content = this.createCodebaseEvolution(hash, stats);
      await ensureDir(path.dirname(evolutionPath));
      await writeFileSafe(evolutionPath, content);
      return;
    }

    // Check if hash changed
    if (!content.includes(`\`${hash}\``)) {
      const timestamp = new Date().toISOString().split('T')[0];
      const entry = `
## ${timestamp} - Scan

**Codebase Hash:** \`${hash}\`
**Files:** ${stats.files}
**LOC:** ${stats.loc}

---
`;
      await writeFileSafe(evolutionPath, content + entry);
    }
  }
}
